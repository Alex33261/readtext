---
output:
  md_document:
    variant: markdown_github
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "images/"
)
```

# readtext: Import and handling for plain and formatted text files

[![CRAN Version](http://www.r-pkg.org/badges/version/readtext)](https://CRAN.R-project.org/package=readtext)
![Downloads](http://cranlogs.r-pkg.org/badges/readtext)
[![Travis-CI Build Status](https://travis-ci.org/kbenoit/readtext.svg?branch=master)](https://travis-ci.org/kbenoit/readtext)
[![codecov.io](https://codecov.io/github/kbenoit/readtext/coverage.svg?branch=master)][1]


[1]: https://codecov.io/gh/kbenoit/readtext/branch/master

An R package for reading text files in all their various formats, by Ken Benoit, Paul Nulty, and Adam Obeng.  (In alphabetical order, not by order of contribution.)

## Introduction

**readtext** is a one-function package that does exactly what it says on the tin: It reads files containing text, along with any associated document-level metadata, which we call "docvars", for document variables.  Plain text files do not have docvars, but other forms such as .csv, .tab, .xml, and .json files usually do.  

**readtext** accepts filemasks, so that you can specify a pattern to load multiple texts, and these texts can even be of multiple types.  **readtext** is smart enough to process them correctly, returning a data.frame with a primary field "text" containing a character vector of the texts, and additional columns of the data.frame as found in the document variables from the source files.

As encoding can also be a challenging issue for those reading in texts, we include functions for diagnosing encodings on a file-by-file basis, and allow you to specify vectorized input encodings to read in file types with individually set (and different) encodings.  (All ecnoding functions are handled by the **stringi** package.)

## Inter-operability with **quanteda**

**readtext** was originally developed in early versions of the [**quanteda**](https://github.com/kbenoit/quanteda) package for the quantitative analysis of textual data.  It was spawned from the `textfile()` function from that package, and now lives exclusively in **readtext**.  Because **quanteda**'s corpus constructor recognizes the data.frame format returned by `readtxt()`, it can construct a corpus directly from a `readtext` object, preserving all docvars and other meta-data.

```{r}
require(readtext)
require(quanteda)

FILEDIR <- tempdir()
unzip(system.file("extdata", "encodedTextFiles.zip", package = "readtext"), exdir = FILEDIR)

# get encoding from filename
filenames <- list.files(FILEDIR, "\\.txt$")
# strip the extension
filenames <- gsub(".txt$", "", filenames)
parts <- strsplit(filenames, "_")
fileencodings <- sapply(parts, "[", 3)
fileencodings

# find out which conversions are unavailable (through iconv())
cat("Encoding conversions not available for this platform:")
notAvailableIndex <- which(!(fileencodings %in% iconvlist()))
fileencodings[notAvailableIndex]

# read in some text files
# try readtxt
txts <- readtxt(paste0(FILEDIR, "/", "*.txt"))
# substring(readtext::texts(txts)[1], 1, 80)  # gibberish
# substring(readtext::texts(txts)[4], 1, 80)  # hex
# substring(readtext::texts(txts)[40], 1, 80) # hex

# read them in again
txts <- readtxt(paste0(FILEDIR,  "/", "*.txt"), encoding = fileencodings)
substring(readtext::texts(txts)[1], 1, 80)  # English
substring(readtext::texts(txts)[4], 1, 80)  # Arabic, looking good 
substring(readtext::texts(txts)[40], 1, 80) # Cyrillic, looking good
substring(readtext::texts(txts)[7], 1, 80)  # Chinese, looking good
substring(readtext::texts(txts)[26], 1, 80) # Hindi, looking good

txts <- readtxt(paste0(FILEDIR, "/", "*.txt"), 
                encoding = fileencodings,
                docvarsfrom = "filenames", 
                docvarnames = c("document", "language", "inputEncoding"))
encodingCorpus <- corpus(txts, textField = "texts", 
                         source = "Created by encoding-tests.R") 
summary(encodingCorpus)
```

Piping works too:
```{r}
require(magrittr)
readtxt(paste0(FILEDIR,  "/", "*.txt"), encoding = fileencodings) %>%
    corpus(textField = "texts") %>% 
        summary
```

## To Do List

1.  Need to tidy up for passing CHECK.  

2.  (Adam) Inspect the **testthat** tests, see my comments.

3.  (Ken) Need to redefine the data.frame method for `quanteda::corpus()` so that it takes
    `textField = "texts"` by default.
    
4.  More conversion methods?  

5.  How can we define methods for `readtext` objects that extend the generics for`texts()` and `docvars()` that are defined in **quanteda**?  We don't want a NAMESPACE conflict so cannot redefine the generics in **readtexts**.



